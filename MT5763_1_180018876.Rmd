---
title: "Bike Share Analysis"
author: "Matthew Coudert"
date: "Saturday September 26th"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
Bike Shares have been rising in popularity over the past few years in many cities all around the world. In order to predict usage of bikes throughout the year, we will explore the relationships between bike usage and other variables, such as day of the year, season, temperature and other meteorlogical variables. After exploring these relationships, we will use this knowledge to build a model in order to predict bike demand throughout the year. For this project, we have data from Washington DC and Seoul, and will use these data to build two distinct models. 

## Downloading Packages Needed
In order to assist us with the data visualization and clean up, we will download 3 packages:

1. **tidyverse**: Assists with putting the data into 'tidy' format
2. **ggplot2**: Makes plotting cleaner and more readable, as well as adding functionality
3. **lubridate**: Makes dates easier to work with in our datasets
```{r packages}
library(tidyverse)
library(ggplot2)
library(lubridate)
```

# Data Cleanup
In order to do analysis on the data, we first need to 'tidy' the data in order to have it in a format that will be easier to work with as well as being in the same format across both datasets for comparison. In order to accomplish this we will put the data into 'tidy' format using the package tidyverse. In order for data to be 'tidy', it must have: "Rows containing differrent observations; columns containing different variables and cells containing values."


## Saving datasets
The messy datasets are saved in the csv format for easy parsing. 
```{r datasets, message = FALSE, warning = FALSE, results = FALSE}
washington_dataset <- read_csv("BikeWashingtonDC.csv")
seoul_dataset <- read_csv("BikeSeoul.csv")
```

## Seoul dataset clean up
This is a lot! I'll go line by line in order to explain what I'm doing. 

1. Piping the dataset into the next variable
2. Selecting only the variables we are going to use in our analysis
3. Removing the times that there is no count within the dataset
4. Renaming the variables in order to be consistent across the two datasets and have a consistent PascalCase naming convention.
5. Save the date as a lubridate date format so it is easier to work with in the analysis
6. Creating a new date variable FullDate that stores both the date and the time of day
7. FullDate eliminates the need to have seperate variables for Date and Hour, so remove these
8. Changing the Holiday variable from a Character type to a Factor with levels "Yes" and "No"
9. Changing the Season variable from a Character type to an Ordered Factor with levels "Spring","Summer","Autumn", and "Winter" in that order. 
```{r seoul_dataset}
seoul_dataset <- seoul_dataset %>%
  select(-c('Visibility (10m)','Dew point temperature(C)','Solar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)','Functioning Day')) %>% 
  filter(!is.na('Rented Bike Count')) %>%
  rename(Date = 'Date',Count = 'Rented Bike Count',Hour = 'Hour', Temperature = 'Temperature(C)', Humidity = 'Humidity(%)', WindSpeed = 'Wind speed (m/s)', Season = 'Seasons', Holiday = 'Holiday') %>%
  mutate(Date = parse_date_time(Date,"dmy")) %>%
  mutate(FullDate = make_datetime(year = year(Date), month = month(Date), day = day(Date), hour = Hour)) %>%
  select(-c(Date,Hour)) %>%
  mutate(Holiday = factor(ifelse(Holiday == "Holiday", "Yes", "No"), levels = c("Yes","No"))) %>%
  mutate(Season = ordered(Season, levels = c("Spring","Summer","Autumn","Winter")))
```

## Washington DC dataset clean up
Similar to the one above I'll go line by line to explain what's going on!

1. Again piping the dataset into the next variables
2. Selecting and renaming the variables we're using for analysis for consistency. 
3. Changing humidity into a percentage format to be consistent with the Seoul dataset. ($=\text{humidity}*100$)
4. Taking the inverse of the normalization function used in the temperature to convert it to Celcius. $f(t) = \frac{t-(-8)}{39-(-8)}$, $f^{-1}(t) = t*(39-(-8))+8$
5. Taking the inverse of the normalization function used for the temperature to convert it to (m/s) from $f(w)=\frac{1}{67}w (km/h)$, $f^{-1}(w)=\frac{w*67*1000}{60^2}$
6. Changing the Seasons from a numeric into an ordered factor in the same order as the Seoul Dataset ("Spring","Summer","Autumn","Winter")
7. Parsing date, putting it into similar FullDate = day-month-year-hour format and removing unneeded Date and Hour variables.
```{r washington_dataset}
washington_dataset <- washington_dataset %>%
  select(c('dteday','cnt','hr','temp','hum','windspeed','season','holiday')) %>%
  rename(Date = 'dteday', Count = 'cnt', Hour = 'hr', Temperature = 'temp', Humidity = 'hum', WindSpeed = 'windspeed', Season = 'season', Holiday = 'holiday') %>%
  mutate(Humidity = Humidity*100) %>%
  mutate(Temperature = Temperature*(39-(-8))+(-8)) %>%
  mutate(WindSpeed = WindSpeed*67*1000/60^2) %>%
  mutate(Season = ifelse(Season == 1, "Winter", Season)) %>%
  mutate(Season = ifelse(Season == 2, "Spring", Season)) %>%
  mutate(Season = ifelse(Season == 3, "Summer", Season)) %>%
  mutate(Season = ifelse(Season == 4, "Autumn", Season)) %>%
  mutate(Season = ordered(Season, levels = c("Spring","Summer","Autumn","Winter"))) %>%
  mutate(Holiday = factor(ifelse(Holiday == 1, "Yes", "No"), levels = c("Yes","No"))) %>%
  mutate(Date = parse_date_time(Date,"ymd")) %>%
  mutate(FullDate = make_datetime(year = year(Date), month = month(Date), day = day(Date), hour = Hour)) %>%
  select(-c(Date,Hour))
```


## Creating big dataset with both Seoul and Washington DC
In order to more easily plot things with facet_wrap, I put all the data into one dataset and added a variable called "City" to denote which city it's coming from. 
```{r big_dataset}
seoul_dataset <- seoul_dataset %>%
  mutate(City = "Seoul")
washington_dataset <- washington_dataset %>%
  mutate(City = "Washington DC")
dataset <- seoul_dataset %>%
  add_row(washington_dataset) %>%
  arrange(Count)
```

# Plotting
In order to gain a better understanding of how each of the variables are related to eachother, we will plot different variables against eachother. 

## Temperature v Day Plot
In order to get a general idea of how the climates in each location change over the seasons, we will plot for both cities a scatter plot of the date versus the temperature for each datapoint (subdivided into hours). In order to plot this and include datasets that have a very different date range, I plotted against the day of the year, starting from January 1st. Additionally, I used stat_smooth to fit a line to estimate the expected temeperature for each day over the year. 
```{r temp_v_day}
temp_plot <- dataset %>%
  ggplot(aes(x = yday(FullDate), y = Temperature)) + 
  geom_point() + 
  xlab("Day of year from January 1st") +
  ylab("Temperature (C)")+
  stat_smooth(data = dataset, mapping = aes(x = yday(FullDate), y = Temperature)) +
  facet_wrap(~City, scales = "free") +
  ggtitle("Temperature over the year in Washington DC and Seoul")
temp_plot
```

## Plotting Season Against Bike Demand
Now that we have explored the temepurature data across the year, it's time to start looking at how each of the explanatory variables affect the number of bikes rented per day. First we'll explore how the season of the year affects how many bikes are rented each day. To visualize this, I plotted a boxplot for each city. There's a clear increase in bike usage during the warmer seasons than in the winter in both cities. There is a more drastic drop in bike usage in Seoul during the winter than in Washington DC, and a question to explore would be whether or not this is due to Washington DC having a comparitively milder winter than Seoul. 
```{r season_v_bike_demand, message=FALSE, warning=FALSE}
season_plot_day <- dataset %>%
  group_by(date(FullDate),City, Season) %>%
  summarise(DayCount = sum(Count)) %>%
  ggplot(aes(x = Season, y = DayCount)) +
  geom_boxplot() + 
  facet_wrap(~City, scales = "free") + 
  ggtitle("Boxplot of Season Versus number of Bikes Rented per Day") +
  xlab("Season") +
  ylab("Number of bikes rented per day") 
season_plot_day
```

## Plotting holiday v bike demand

```{r holiday_v_bike_demand}
holiday_plot <- dataset %>%
  group_by(date(FullDate), City, Holiday) %>%
  summarise(DayCount = sum(Count)) %>%
  ggplot(aes(x = Holiday, y = DayCount)) +
  geom_boxplot() +
  facet_wrap(~City, scales = "free") +
  ggtitle("Boxplot of Holiday versus number of Bikes rented per day") +
  xlab("Holiday") +
  ylab("Number of bikes rented per day")
holiday_plot
```

## Plotting weather variables v bike demand
```{r weather_v_bike_demand, message=FALSE, warning=FALSE}
air_temp_plot <- dataset %>%
  ggplot(aes(x = Temperature, y = Count)) +
  geom_point() +
  facet_wrap(~City, scale = "free") +
  stat_smooth(data = dataset, mapping = aes(x = Temperature, y = Count), formula = y ~ x) +
  ggtitle("Temperature vs Bike Rental") +
  ylab("Number of bikes hired per hour")
air_temp_plot

humidity_plot <- dataset %>%
  ggplot(aes(x = Humidity, y = Count)) +
  geom_point() +
  facet_wrap(~City, scale = "free") +
  stat_smooth(data = dataset, mapping = aes(x = Humidity, y = Count), formula = y ~ x) +
  ggtitle("Humidity vs Bike Rental") +
  ylab("Number of bikes hired per hour")
humidity_plot

wind_plot <- dataset %>%
  ggplot(aes(x = WindSpeed, y = Count)) +
  geom_point() +
  facet_wrap(~City, scale = "free") +
  stat_smooth(data = dataset, mapping = aes(x = WindSpeed, y = Count), formula = y ~ x) +
  ggtitle("WindSpeed (m/s) vs Bike Rental") +
  ylab("Number of bikes hired per hour")
wind_plot
```


# STATISTICAL MODELLING

## Linear Model for Seoul
In order to deal with the nominal categorical variable Season, I created n-1 dummy variables where a value is 1 if it is that season and 0 otherwise. 
```{r linear_seoul}
seoul_model_dataset <- seoul_dataset %>%
  mutate(Winter = ifelse(Season == "Winter", 1, 0)) %>%
  mutate(Spring = ifelse(Season == "Spring", 1, 0)) %>%
  mutate(Summer = ifelse(Season == "Summer", 1, 0))

seoul_model <- lm(formula = log(Count + 1) ~ Winter + Spring + Summer + Temperature + Humidity + WindSpeed, data = seoul_model_dataset)
summary(seoul_model)
```

## Linear model for Washington DC
```{r linear_washington}
washington_model_dataset <- washington_dataset %>%
  mutate(Winter = ifelse(Season == "Winter", 1, 0)) %>%
  mutate(Spring = ifelse(Season == "Spring", 1, 0)) %>%
  mutate(Summer = ifelse(Season == "Summer", 1, 0))


washington_model <- lm(formula = log(Count + 1) ~ Winter + Spring + Summer + Temperature + Humidity + WindSpeed, data = washington_model_dataset)
summary(washington_model)

```
## Model Analysis
A linear model is built on the assumptions that the errors of the model are independent and identically normally distributed with mean 0 and variance $\sigma^2$. Below the plotted Normal Q-Q plots show that 
```{r model_analysis}
washington_residuals <- resid(washington_model)
seoul_residuals <- resid(seoul_model)


par(mfrow = c(2,2))
plot(washington_model)

plot(seoul_model)

```

## Confidence Intervals for Models
Here, I've generated a 97% confidence interval for each of the variables. The Washington DC model differs pretty greatly from the model for Seoul in that it has negative coefficients for for all of the Seasons and has a greater coefficient for temperature in order to compensate for this difference. 
```{r confidence_intervals}
confint(seoul_model, level = 0.97) 
confint(washington_model, level = 0.97)

example_predict <- data.frame(Temperature = 0,
                              WindSpeed = 0.5,
                              Humidity = 20,
                              Winter = 1,
                              Spring = 0,
                              Summer = 0)
log_seoul_predict <- predict(seoul_model, interval = "prediction", level = 0.90, newdata = example_predict)
log_washington_predict <- predict(washington_model, interval = "prediction", level = 0.90, newdata = example_predict)
```

